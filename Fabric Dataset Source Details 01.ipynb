{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2aa9283-dab8-4967-bd17-754c222d7a1b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:52.0595124Z",
       "execution_start_time": "2025-04-23T05:53:51.6093852Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7db0e3e5-7a3a-4bb1-9fef-0352da57d670",
       "queued_time": "2025-04-23T05:53:51.6074503Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 31,
       "statement_ids": [
        31
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 31, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "from pyspark.sql.functions import col\n",
    "import msal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c0caa-e812-40ea-92f9-4cdf8cb39fbb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:52.4256957Z",
       "execution_start_time": "2025-04-23T05:53:52.0625126Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "a1a49cdd-8649-4221-addb-d089c67f3c49",
       "queued_time": "2025-04-23T05:53:51.6821709Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 32,
       "statement_ids": [
        32
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 32, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Azure AD Credentials (Replace with your values)\n",
    "TENANT_ID = \"\"\n",
    "CLIENT_ID = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "\n",
    "# Azure AD Authority & Scope\n",
    "# AUTHORITY = f\"https://login.microsoftonline.com/{TENANT_ID}\"\n",
    "# SCOPE = [\"https://api.fabric.microsoft.com/.default\"]  # Fabric API Scope\n",
    "# TOKEN_URL = f\"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token\"\n",
    "\n",
    "AUTHORITY = f\"https://login.microsoftonline.com/{TENANT_ID}\"\n",
    "SCOPE = [\"https://analysis.windows.net/powerbi/api/.default\"]  # Power BI Scpoe\n",
    "TOKEN_URL = f\"https://login.microsoftonline.com/{TENANT_ID}/oauth2/token\"\n",
    "\n",
    "\n",
    "\n",
    "# Global variables for token caching\n",
    "ACCESS_TOKEN = None\n",
    "EXPIRATION_TIME = 0  # Store expiration time\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"Fetch and cache an access token from Azure AD for Power BI API.\"\"\"\n",
    "    global ACCESS_TOKEN, EXPIRATION_TIME\n",
    "\n",
    "    # Check if token is still valid\n",
    "    if ACCESS_TOKEN and time.time() < EXPIRATION_TIME:\n",
    "        return ACCESS_TOKEN  # Return cached token if still valid\n",
    "\n",
    "    # Create MSAL client application\n",
    "    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=AUTHORITY, client_credential=CLIENT_SECRET)\n",
    "\n",
    "    # Acquire token\n",
    "    token_response = app.acquire_token_for_client(scopes=SCOPE)\n",
    "\n",
    "    if \"access_token\" in token_response:\n",
    "        ACCESS_TOKEN = token_response[\"access_token\"]\n",
    "        EXPIRATION_TIME = time.time() + token_response.get(\"expires_in\", 3600) - 300  # Refresh 5 minutes before expiry\n",
    "        return ACCESS_TOKEN\n",
    "    else:\n",
    "        raise Exception(f\"Failed to get token: {token_response}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edc34538-b08b-4fa6-9ac4-50555a1017ef",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:53.3808854Z",
       "execution_start_time": "2025-04-23T05:53:52.4286571Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "8b6facbf-dd79-41ab-8661-50dd46af54b3",
       "queued_time": "2025-04-23T05:53:51.7569755Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 33,
       "statement_ids": [
        33
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 33, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reading the Datafrom the delta file\n",
    "workspacess_df = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .load(\"abfss://d3120490-76ae-4ef4-a440-2bd65732ccdc@onelake.dfs.fabric.microsoft.com/fecab367-5d3a-41c1-8037-7801192932ba/Tables/fabric_workpsaces\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1499b542-a5d2-473d-8796-98e2d2bfe1a4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:54.4373808Z",
       "execution_start_time": "2025-04-23T05:53:53.3834836Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "799415f6-cfe7-4c04-a7a4-7e6095c96ce4",
       "queued_time": "2025-04-23T05:53:51.930256Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 34,
       "statement_ids": [
        34
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 34, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Filter Workspaces for a capactity\n",
    "filtered_workspaces_df = workspacess_df.filter(col(\"capacityId\") == \"76F4499E-05FF-44A9-8C2F-323EE14EA1A7\")\n",
    "workspaceIds_list = [row[\"id\"] for row in filtered_workspaces_df.select(\"id\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc68601f-cc1c-40e7-9ffb-73f5952dce81",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:54.7647236Z",
       "execution_start_time": "2025-04-23T05:53:54.4404751Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "29811dca-ae32-408d-b3b3-c147a484ead4",
       "queued_time": "2025-04-23T05:53:52.075011Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 35,
       "statement_ids": [
        35
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 35, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reading the Datafrom the delta file\n",
    "datasets_df = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .load(\"abfss://d3120490-76ae-4ef4-a440-2bd65732ccdc@onelake.dfs.fabric.microsoft.com/fecab367-5d3a-41c1-8037-7801192932ba/Tables/datasets\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53ae5ff8-8296-4601-8236-922a0721d3b9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:55.7413854Z",
       "execution_start_time": "2025-04-23T05:53:54.767701Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "d8a6e496-6d18-415d-a1da-d734da4e4a71",
       "queued_time": "2025-04-23T05:53:52.228738Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 36,
       "statement_ids": [
        36
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 36, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Filter Datsets for a capactity\n",
    "filtered_datasets_df = datasets_df.filter(col(\"workspaceId\").isin(workspaceIds_list))\n",
    "datasetIds_list = [row[\"id\"] for row in filtered_datasets_df.select(\"id\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e274ee01-7d17-4f11-a74e-3f9d44b58b46",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:53:56.0926807Z",
       "execution_start_time": "2025-04-23T05:53:55.7449478Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "41cc47d1-7ac9-47cd-8ea8-e8864e5a71fb",
       "queued_time": "2025-04-23T05:53:52.480908Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 37,
       "statement_ids": [
        37
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 37, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_dataset_datasource_details(workspaceId, datasetId):\n",
    "    \"\"\"Fetch dataset datasource details from Power BI API and return as a DataFrame with all data sources.\"\"\"\n",
    "    token = get_access_token()\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/datasources\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    status_code = response.status_code\n",
    "\n",
    "    records = []\n",
    "\n",
    "    if status_code == 200:\n",
    "        try:\n",
    "            source_data = response.json().get(\"value\", [])\n",
    "            for details in source_data:\n",
    "                connection = details.get(\"connectionDetails\", {})\n",
    "\n",
    "                # Extract server/path/db name\n",
    "                if \"path\" in connection and \"kind\" in connection:\n",
    "                    server_path = connection.get(\"path\")\n",
    "                    db_kind = connection.get(\"kind\")\n",
    "                elif \"server\" in connection and \"database\" in connection:\n",
    "                    server_path = connection.get(\"server\")\n",
    "                    db_kind = connection.get(\"database\")\n",
    "                elif \"url\" in connection:\n",
    "                    server_path = connection.get(\"url\")\n",
    "                    db_kind = \"NA\"\n",
    "                else:\n",
    "                    server_path = str(connection)\n",
    "                    db_kind = \"NA\"\n",
    "\n",
    "                record = {\n",
    "                    \"WorkspaceID\": workspaceId,\n",
    "                    \"DatasetID\": datasetId,\n",
    "                    \"DatasourceType\": details.get(\"datasourceType\", \"NA\"),\n",
    "                    \"Server_Path\": server_path,\n",
    "                    \"Database_Kind\": db_kind,\n",
    "                    \"DatasourceID\": details.get(\"datasourceId\", \"NA\"),\n",
    "                    \"GatewayID\": details.get(\"gatewayId\", \"NA\"),\n",
    "                    \"StatusCode\": status_code\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "            # If the list is empty, still add a row for tracking\n",
    "            if not source_data:\n",
    "                records.append({\n",
    "                    \"WorkspaceID\": workspaceId,\n",
    "                    \"DatasetID\": datasetId,\n",
    "                    \"DatasourceType\": \"NA\",\n",
    "                    \"Server_Path\": \"NA\",\n",
    "                    \"Database_Kind\": \"NA\",\n",
    "                    \"DatasourceID\": \"NA\",\n",
    "                    \"GatewayID\": \"NA\",\n",
    "                    \"StatusCode\": status_code\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            records.append({\n",
    "                \"WorkspaceID\": workspaceId,\n",
    "                \"DatasetID\": datasetId,\n",
    "                \"DatasourceType\": \"NA\",\n",
    "                \"Server_Path\": \"NA\",\n",
    "                \"Database_Kind\": \"NA\",\n",
    "                \"DatasourceID\": \"NA\",\n",
    "                \"GatewayID\": \"NA\",\n",
    "                \"StatusCode\": status_code\n",
    "            })\n",
    "    else:\n",
    "        records.append({\n",
    "            \"WorkspaceID\": workspaceId,\n",
    "            \"DatasetID\": datasetId,\n",
    "            \"DatasourceType\": \"NA\",\n",
    "            \"Server_Path\": \"NA\",\n",
    "            \"Database_Kind\": \"NA\",\n",
    "            \"DatasourceID\": \"NA\",\n",
    "            \"GatewayID\": \"NA\",\n",
    "            \"StatusCode\": status_code\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c04010b-3c3d-4c20-bb94-73470b3d0a07",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:54:05.7687747Z",
       "execution_start_time": "2025-04-23T05:53:57.4221439Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "91a96d6a-7d46-4737-98e0-3e7f180f203a",
       "queued_time": "2025-04-23T05:53:53.1129285Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 40,
       "statement_ids": [
        40
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 40, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_temp_dfs = pd.DataFrame()  # List to store non-empty DataFrames\n",
    "\n",
    "for row in filtered_datasets_df.toLocalIterator():  # No need for unpacking\n",
    "\n",
    "    temp_df = get_dataset_datasource_details(row[\"workspaceId\"], row[\"id\"])\n",
    "\n",
    "    all_temp_dfs = pd.concat([all_temp_dfs, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d820e74e-3faf-4e62-b332-1006197c1de6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:54:06.1164078Z",
       "execution_start_time": "2025-04-23T05:54:05.7720191Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "ee34e026-034a-4372-83ef-d7301ddca4b9",
       "queued_time": "2025-04-23T05:53:53.2667553Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 41,
       "statement_ids": [
        41
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 41, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_dataset_source_details_df = spark.createDataFrame(all_temp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0d18738-57b7-4144-93d9-f7d2195b12b4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:54:06.4402847Z",
       "execution_start_time": "2025-04-23T05:54:06.119596Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "5a6853c6-5820-4b7f-9a5d-3ef91180c158",
       "queued_time": "2025-04-23T05:53:53.5523748Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 42,
       "statement_ids": [
        42
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 42, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reading the Datafrom the delta file\n",
    "existing_datasets_source_details = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .load(\"abfss://d3120490-76ae-4ef4-a440-2bd65732ccdc@onelake.dfs.fabric.microsoft.com/fecab367-5d3a-41c1-8037-7801192932ba/Tables/datasets_source_details\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a310069d-ab56-43d3-97bb-3c715a74e896",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:54:06.7919843Z",
       "execution_start_time": "2025-04-23T05:54:06.4428357Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "c0f347a5-f612-4339-898b-2adec963a0dc",
       "queued_time": "2025-04-23T05:53:53.7295362Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 43,
       "statement_ids": [
        43
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 43, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, get only the new DatasetIDs\n",
    "new_records_df = spark_dataset_source_details_df.join(\n",
    "    existing_datasets_source_details,\n",
    "    on=\"DatasetID\",\n",
    "    how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# Append new records to existing dataset\n",
    "updated_datasets_source_details = existing_datasets_source_details.unionByName(new_records_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07962dc1-7062-4402-b1ee-1b3d0ba5549a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-23T05:54:15.2054516Z",
       "execution_start_time": "2025-04-23T05:54:06.7948881Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "710ebaeb-07a3-4a96-9f79-4acbd84ea225",
       "queued_time": "2025-04-23T05:53:53.987465Z",
       "session_id": "9a49198d-9ad9-4fcd-a7a1-35369c3badbc",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 44,
       "statement_ids": [
        44
       ]
      },
      "text/plain": [
       "StatementMeta(, 9a49198d-9ad9-4fcd-a7a1-35369c3badbc, 44, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_datasets_source_details.write.mode(\"overwrite\").saveAsTable(\"datasets_source_details\")"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "fecab367-5d3a-41c1-8037-7801192932ba",
    "default_lakehouse_name": "Fabric",
    "default_lakehouse_workspace_id": "d3120490-76ae-4ef4-a440-2bd65732ccdc",
    "known_lakehouses": [
     {
      "id": "fecab367-5d3a-41c1-8037-7801192932ba"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
